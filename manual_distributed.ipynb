{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:15:58.970463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 13:15:59.516707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2023-11-10 13:15:59.516750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2023-11-10 13:15:59.516756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing dataset wt103...\n",
      "final vocab size 109697 from 109695 unique tokens\n"
     ]
    }
   ],
   "source": [
    "##data load ### cpu 버전\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from data_cpu import Dataset, LMOrderedIterator\n",
    "from model import TFTransfoXLModel,TFTransfoXLLMHeadModel\n",
    "\n",
    "from transformers import TransfoXLConfig\n",
    "\n",
    "\n",
    "config_xl = TransfoXLConfig(\n",
    "    data = '/home/jun/workspace/wiki_short/',\n",
    "    dataset = 'wt103',\n",
    "    d_embed=128,\n",
    "    d_head = 32,\n",
    "    d_model=128,\n",
    "    mem_len=400,\n",
    "    n_head=8,\n",
    "    n_layer=6,\n",
    "    batch_size = 18,\n",
    "    tgt_len = 36,\n",
    "    ext_len = 0,\n",
    "    eval_tgt_len = 36\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {}\n",
    "if config_xl.dataset in ['wt103', 'wt2']:\n",
    "    kwargs['special'] = ['<eos>','<UNK>']\n",
    "    kwargs['lower_case'] = False\n",
    "\n",
    "dataset = Dataset(**kwargs)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = dataset.make_dataset(config_xl.data,config_xl.dataset)\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산처리를 하기위해서는 train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "이 코드를 실행해야하는데ㅐ 기본 텐서 구조는 안되더라 그래서 텐서 슬라이스 변경해서 이 구조로 바꾸고 데이터를 이터레이션 해서 모델에 집어 넣어야 하는 방식을 고민중 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(data,bsz,bptt,ext_len=None,):\n",
    "  \n",
    "  bsz = bsz#3 #60\n",
    "  bptt = bptt#36 #70\n",
    "  ext_len = ext_len if ext_len is not None else 0\n",
    "  data = data\n",
    "  \n",
    "  \n",
    "  # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "  # 아래의 두 코드는   data 텐서에서 배치 크기 bsz로 깔끔하게 맞지 않는 추가 요소를 제거하는 것 배치에 띡 떨어지게\n",
    "  n_step = len(data) // (bsz*bptt)\n",
    "  print('n_step',n_step) # 312779\n",
    "  \n",
    "  sliced_data = tf.slice(data,[0],[n_step * bsz*bptt])  \n",
    "  # print('sliced_data',len(sliced_data))\n",
    "  # sliced_data = self.data[:self.n_step * self.bsz]\n",
    "  '''# 시작 위치와 슬라이싱할 크기 설정\n",
    "  begin = [0]  # 첫 번째 차원의 시작 위치는 0\n",
    "  size = [6]   # 첫 번째 차원에서 6개의 원소를 슬라이싱\n",
    "\n",
    "  # 데이터를 잘라내기 (tf.slice 사용)\n",
    "  sliced_data = tf.slice(data, begin, size)  '''\n",
    "\n",
    "  # Evenly divide the da\n",
    "  # ta across the bsz batches.\n",
    "\n",
    "\n",
    "  new_shape = (bsz, -1)  # 나머지 차원은 자동으로 계산됨\n",
    "  data_reshaped = tf.reshape(sliced_data, new_shape)\n",
    "  # data_transposed = tf.transpose(data_reshaped)\n",
    "  data = data_reshaped\n",
    "  # print('data',len(data))\n",
    "  split_num = 2 #GPU num\n",
    "\n",
    "\n",
    "  # first_half, second_half = tf.split(data, num_or_size_splits=split_num, axis=1)\n",
    "\n",
    "  n_batch = (n_step + bptt - 1) // bptt\n",
    "\n",
    "  for i in range(0, len(data[1]) - 1, bptt):\n",
    "    \n",
    "    seq_len = min(bptt, data.shape[1] - 1 - i) # # i값이 103227020를 넘지 않는 이상 seq_len = 70\n",
    "\n",
    "\n",
    "    end_idx = i + seq_len # 70,71,72,73,74......\n",
    "    beg_idx = max(0, i - ext_len) # 0,1,2,3,4,5\n",
    "    ''' 아래 처럼 첫번째 차원을 자르는 이류\n",
    "    로,또,1,등,당,첨 = > 로,또,1    => 로, 등\n",
    "                    등,당,첨         또, 당\n",
    "                                    1, 첨\n",
    "    '''\n",
    "\n",
    "    p_data = data[:,beg_idx:end_idx] # self.data[:,0:70],[:,1:71] ~\n",
    "    target = data[:,i+1:i+1+seq_len]\n",
    "\n",
    "    # second_half_data = second_half[:,beg_idx:end_idx] # self.data[:,0:70],[:,1:71] ~\n",
    "    # second_half_target = second_half[:,i+1:i+1+seq_len]\n",
    "    if i + bptt < len(data[1]) - 1:\n",
    "      yield p_data, target\n",
    "      # yield second_half_data, second_half_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:16:05.084625: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.085006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.090363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.090722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.091061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.091395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.092029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 13:16:05.185069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.185393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.185648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.185890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.186132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.186372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.764466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.764781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.765048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.765346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.765590: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.765829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6638 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-11-10 13:16:05.766098: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 13:16:05.766328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6638 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=None, dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.int32),\n",
    "         ),\n",
    "     args=(train_dataset,config_xl.batch_size,config_xl.tgt_len)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step 8688\n",
      "8687\n"
     ]
    }
   ],
   "source": [
    "count =0 \n",
    "for sample in dataset:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_half_dataset = dataset.take(count//2)\n",
    "second_half_dataset = dataset.skip((count // 2) + (count % 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts =0 \n",
    "# for sample in second_half_dataset:\n",
    "#     counts += 1\n",
    "# print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# BATCH_SIZE_PER_REPLICA = 1\n",
    "# GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dist_dataset = strategy.experimental_distribute_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched_dataset =dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "# batched_dataset.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count =0 \n",
    "# for sample in batched_dataset:\n",
    "#     print(sample[0].shape)\n",
    "#     print(sample[1].shape)\n",
    "#     count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import horovod.tensorflow as hvd\n",
    "\n",
    "\n",
    "# # Horovod 초기화\n",
    "# hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "#     def __init__(self, d_model, warmup_steps=4000):\n",
    "#         super(CustomSchedule, self).__init__()\n",
    "\n",
    "#         self.d_model = tf.cast(d_model, tf.float32)\n",
    "#         self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "\n",
    "#     def __call__(self, step):\n",
    "#         step = tf.cast(step, tf.float32)\n",
    "#         arg1 = tf.math.rsqrt(step)\n",
    "#         arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "#         # Horovod의 크기(hvd.size())로 학습률을 스케일링합니다.\n",
    "#         return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2) * hvd.size()\n",
    "\n",
    "# @tf.keras.utils.register_keras_serializable()\n",
    "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "#     def __init__(self, d_model, warmup_steps=4000):\n",
    "#         super(CustomSchedule, self).__init__()\n",
    "\n",
    "#         self.d_model = tf.cast(d_model, tf.float32)\n",
    "#         self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "\n",
    "#     def __call__(self, step):\n",
    "#         step = tf.cast(step, tf.float32)  # step을 float32로 명시적 캐스팅\n",
    "#         arg1 = tf.math.rsqrt(step)\n",
    "#         arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "#         # tf.math.rsqrt(self.d_model)를 float32로 캐스팅합니다.\n",
    "#         # hvd.size()는 이미 float32로 캐스팅되었다고 가정합니다.\n",
    "#         return tf.math.rsqrt(self.d_model, tf.float32) * tf.math.minimum(arg1, arg2) * tf.cast(hvd.size(), tf.float32)\n",
    "\n",
    "\n",
    "    \n",
    "#     def get_config(self):\n",
    "#         return {\n",
    "#             'd_model': self.d_model if isinstance(self.d_model, float) else self.d_model.numpy(),  \n",
    "#             'warmup_steps': self.warmup_steps if isinstance(self.warmup_steps, float) else self.warmup_steps.numpy()\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = tf.cast(warmup_steps,tf.float32)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step =tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(config_xl.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "def compute_loss(loss):\n",
    "\n",
    "    return tf.nn.compute_average_loss(loss, global_batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# optimizer1 = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "#                                      epsilon=1e-9)\n",
    "# optimizer2 = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "#                                      epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model0 = TFTransfoXLLMHeadModel(config=config_xl)\n",
    "\n",
    "\n",
    "model1 = TFTransfoXLLMHeadModel(config=config_xl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(model,data,target,mems,optimizer):\n",
    "\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    outputs = model(input_ids=data,labels=target,mems=mems)\n",
    "    # loss = compute_loss(outputs.loss)\n",
    "    mems = outputs.mems\n",
    "\n",
    "  gradients = tape.gradient(outputs.loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  return mems,outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step 8688\n",
      "n_step 8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:16:48.185113: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x563787750180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-10 13:16:48.185133: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2023-11-10 13:16:48.185136: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2023-11-10 13:16:48.188500: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-10 13:16:48.266089: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ffb4dd2e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ffb4dd2e430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "loss [<tf.Tensor: shape=(), dtype=float32, numpy=10.723874>]\n",
      "Epoch 1 Batch 0 Loss [<tf.Tensor: shape=(), dtype=float32, numpy=10.723874>]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/workspace/transfo_xl/manual_distributed.ipynb 셀 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/manual_distributed.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Batch \u001b[39m\u001b[39m{\u001b[39;00mnum_batches\u001b[39m}\u001b[39;00m\u001b[39m Loss \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/manual_distributed.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# 가중치 동기화\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/manual_distributed.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m hvd\u001b[39m.\u001b[39;49mallreduce([loss], average\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/manual_distributed.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/manual_distributed.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# 로그 출력\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/horovod/tensorflow/__init__.py:136\u001b[0m, in \u001b[0;36mallreduce\u001b[0;34m(tensor, average, device_dense, device_sparse, compression, op, prescale_factor, postscale_factor, name, process_set, ignore_name_scope)\u001b[0m\n\u001b[1;32m    131\u001b[0m     op \u001b[39m=\u001b[39m Sum \u001b[39mif\u001b[39;00m op \u001b[39m==\u001b[39m Average \u001b[39melse\u001b[39;00m op\n\u001b[1;32m    133\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(device_dense):\n\u001b[1;32m    134\u001b[0m     horovod_size \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(size_op(process_set_id\u001b[39m=\u001b[39mprocess_set\u001b[39m.\u001b[39mprocess_set_id)\n\u001b[1;32m    135\u001b[0m                            \u001b[39mif\u001b[39;00m \u001b[39mint\u001b[39m(os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mHOROVOD_ELASTIC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)) \u001b[39melse\u001b[39;00m process_set\u001b[39m.\u001b[39msize(),\n\u001b[0;32m--> 136\u001b[0m                            dtype\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39;49mdtype)\n\u001b[1;32m    137\u001b[0m     tensor_compressed, ctx \u001b[39m=\u001b[39m compression\u001b[39m.\u001b[39mcompress(tensor)\n\u001b[1;32m    138\u001b[0m     summed_tensor_compressed \u001b[39m=\u001b[39m _allreduce(tensor_compressed, op\u001b[39m=\u001b[39mop,\n\u001b[1;32m    139\u001b[0m                                           prescale_factor\u001b[39m=\u001b[39mprescale_factor,\n\u001b[1;32m    140\u001b[0m                                           postscale_factor\u001b[39m=\u001b[39mpostscale_factor,\n\u001b[1;32m    141\u001b[0m                                           name\u001b[39m=\u001b[39mname, process_set\u001b[39m=\u001b[39mprocess_set,\n\u001b[1;32m    142\u001b[0m                                           ignore_name_scope\u001b[39m=\u001b[39mignore_name_scope)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    mems1 = None\n",
    "    mems2 = None\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for (frist_data, frist_target), (second_data,second_target) in zip(first_half_dataset,second_half_dataset):\n",
    "        with tf.device('/GPU:0'):\n",
    "\n",
    "            mems,loss = train_step(model0,frist_data,frist_target,mems1,optimizer1)\n",
    "            print('loss',loss)\n",
    "            total_loss += loss[0].numpy()\n",
    "            if num_batches % 50 == 0:\n",
    "                print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss}')\n",
    "        # 가중치 복사\n",
    "        weights_gpu0 = model0.get_weights()\n",
    "        \n",
    "        with tf.device('/GPU:1'):\n",
    "\n",
    "            mems,loss = train_step(model1,second_data,second_target,mems2,optimizer2)\n",
    "            total_loss += loss[0].numpy()\n",
    "            num_batches += 1\n",
    "            if num_batches % 50 == 0:\n",
    "                print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss}')\n",
    "\n",
    "\n",
    "\n",
    "        # 가중치 복사\n",
    "        weights_gpu1 = model1.get_weights()\n",
    "        \n",
    "        # 가중치 평균 계산 및 동기화\n",
    "        average_weights = [(w0 + w1) / 2.0 for w0, w1 in zip(weights_gpu0, weights_gpu1)]\n",
    "        \n",
    "        # 두 모델의 가중치 업데이트\n",
    "        model0.set_weights(average_weights)\n",
    "        model1.set_weights(average_weights)\n",
    "\n",
    "# 에포크마다 평균 손실을 기록\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f'Epoch {epoch + 1}, Loss: {avg_loss}, Time: {time.time() - start}')\n",
    "\n",
    "\n",
    "        #     if num_batches % 50 == 0:\n",
    "        #         print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss}')\n",
    "            \n",
    "        # train_loss = total_loss / num_batches\n",
    "            \n",
    "            \n",
    "        # template = (\"Epoch {}, Loss: {} \")\n",
    "        # print(template.format(epoch + 1, train_loss,\n",
    "        #                         )) \n",
    "# checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "    # ckpt = tf.train.Checkpoint(transformer=model,\n",
    "    #                         optimizer=optimizer)\n",
    "\n",
    "    # ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "    # # if a checkpoint exists, restore the latest checkpoint.\n",
    "    # if ckpt_manager.latest_checkpoint:\n",
    "    #     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    #     print('Latest checkpoint restored!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
