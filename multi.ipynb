{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 18:26:50.192175: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 18:26:50.746766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2023-11-16 18:26:50.746809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64:\n",
      "2023-11-16 18:26:50.746814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing dataset wt103...\n",
      "final vocab size 109697 from 109695 unique tokens\n"
     ]
    }
   ],
   "source": [
    "##data load ### cpu 버전\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from data_cpu import Dataset, LMOrderedIterator\n",
    "from model import TFTransfoXLModel,TFTransfoXLLMHeadModel\n",
    "\n",
    "from transformers import TransfoXLConfig\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "config_xl = TransfoXLConfig(\n",
    "    data = '/home/jun/workspace/wiki_short/',\n",
    "    dataset = 'wt103',\n",
    "    d_embed=128,\n",
    "    d_head = 2,\n",
    "    d_model=10,\n",
    "    mem_len=5,\n",
    "    n_head=2,\n",
    "    n_layer=6,\n",
    "    batch_size = 2,\n",
    "    tgt_len = 3,\n",
    "    ext_len = 0,\n",
    "    eval_tgt_len = 36\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "kwargs = {}\n",
    "if config_xl.dataset in ['wt103', 'wt2']:\n",
    "    kwargs['special'] = ['<eos>','<UNK>']\n",
    "    kwargs['lower_case'] = False\n",
    "\n",
    "dataset = Dataset(**kwargs)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = dataset.make_dataset(config_xl.data,config_xl.dataset)\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400 // 10*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산처리를 하기위해서는 train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "이 코드를 실행해야하는데ㅐ 기본 텐서 구조는 안되더라 그래서 텐서 슬라이스 변경해서 이 구조로 바꾸고 데이터를 이터레이션 해서 모델에 집어 넣어야 하는 방식을 고민중 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(data,bsz,bptt,ext_len=None,):\n",
    "  \n",
    "  bsz = bsz#3 #60\n",
    "  bptt = bptt#36 #70\n",
    "  ext_len = ext_len if ext_len is not None else 0\n",
    "  data = data\n",
    "  \n",
    "  \n",
    "  # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "  # 아래의 두 코드는   data 텐서에서 배치 크기 bsz로 깔끔하게 맞지 않는 추가 요소를 제거하는 것 배치에 띡 떨어지게\n",
    "  n_step = len(data) // (bsz*bptt)\n",
    "  print('n_step',n_step) # 312779\n",
    "  \n",
    "  sliced_data = tf.slice(data,[0],[n_step * bsz*bptt])  \n",
    "  # print('sliced_data',len(sliced_data))\n",
    "  # sliced_data = self.data[:self.n_step * self.bsz]\n",
    "  '''# 시작 위치와 슬라이싱할 크기 설정\n",
    "  begin = [0]  # 첫 번째 차원의 시작 위치는 0\n",
    "  size = [6]   # 첫 번째 차원에서 6개의 원소를 슬라이싱\n",
    "\n",
    "  # 데이터를 잘라내기 (tf.slice 사용)\n",
    "  sliced_data = tf.slice(data, begin, size)  '''\n",
    "\n",
    "  # Evenly divide the da\n",
    "  # ta across the bsz batches.\n",
    "\n",
    "\n",
    "  new_shape = (bsz, -1)  # 나머지 차원은 자동으로 계산됨\n",
    "  data_reshaped = tf.reshape(sliced_data, new_shape)\n",
    "  # data_transposed = tf.transpose(data_reshaped)\n",
    "  data = data_reshaped\n",
    "  # print('data',len(data))\n",
    "  split_num = 2 #GPU num\n",
    "\n",
    "\n",
    "  first_half, second_half = tf.split(data, num_or_size_splits=split_num, axis=1)\n",
    "\n",
    "  n_batch = (n_step + bptt - 1) // bptt\n",
    "\n",
    "  for i in range(0, len(first_half[1]) - 1, bptt):\n",
    "    \n",
    "    seq_len = min(bptt, first_half.shape[1] - 1 - i) # # i값이 103227020를 넘지 않는 이상 seq_len = 70\n",
    "\n",
    "\n",
    "    end_idx = i + seq_len # 70,71,72,73,74......\n",
    "    beg_idx = max(0, i - ext_len) # 0,1,2,3,4,5\n",
    "    ''' 아래 처럼 첫번째 차원을 자르는 이류\n",
    "    로,또,1,등,당,첨 = > 로,또,1    => 로, 등\n",
    "                    등,당,첨         또, 당\n",
    "                                    1, 첨\n",
    "    '''\n",
    "\n",
    "    first_half_data = first_half[:,beg_idx:end_idx] # self.data[:,0:70],[:,1:71] ~\n",
    "    first_half_target = first_half[:,i+1:i+1+seq_len]\n",
    "\n",
    "    second_half_data = second_half[:,beg_idx:end_idx] # self.data[:,0:70],[:,1:71] ~\n",
    "    second_half_target = second_half[:,i+1:i+1+seq_len]\n",
    "    if i + bptt < len(first_half[1]) - 1:\n",
    "      yield first_half_data, first_half_target\n",
    "      yield second_half_data, second_half_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 18:26:55.562153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.562476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.566685: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.567021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.567306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.567626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.568208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-16 18:26:55.694596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.694899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.695163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.695413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.695662: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:55.695911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.281733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.282050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.282322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.282577: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.282828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.283074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6632 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-11-16 18:26:56.283348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-16 18:26:56.283582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6632 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "     gen,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=None, dtype=tf.int32),\n",
    "         tf.TensorSpec(shape=None, dtype=tf.int32),\n",
    "         ),\n",
    "     args=(train_dataset,config_xl.batch_size,config_xl.tgt_len)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample=next(iter(dataset))\n",
    "# print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 1\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-16 18:26:56.500579: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dist_dataset = strategy.experimental_distribute_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.int32, name=None), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_dataset =dataset.batch(GLOBAL_BATCH_SIZE)\n",
    "batched_dataset.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count =0 \n",
    "# for sample in batched_dataset:\n",
    "#     # print(sample[0].shape)\n",
    "#     # print(sample[1].shape)\n",
    "#     count += 1\n",
    "# # print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = tf.cast(warmup_steps,tf.float32)\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step =tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(config_xl.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  def compute_loss(loss):\n",
    "    \n",
    "    return tf.nn.compute_average_loss(loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "    model = TFTransfoXLLMHeadModel(config=config_xl)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)\n",
    "    checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "    ckpt = tf.train.Checkpoint(transformer=model,\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "    ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "    # if a checkpoint exists, restore the latest checkpoint.\n",
    "    if ckpt_manager.latest_checkpoint:\n",
    "        ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "        print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(data,target,mems):\n",
    "\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    outputs = model(input_ids=data,labels=target,mems=mems)\n",
    "    loss = compute_loss(outputs.loss)\n",
    "    mems = outputs.mems\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  return mems,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs,target,mems):\n",
    "  mems,per_replica_losses = strategy.run(train_step, args=(dataset_inputs,target,mems))\n",
    "  return mems,strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_step 938338\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "BD_rel_shift Tensor(\"tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._0/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._1/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._2/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._3/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._4/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "rw_head_q (3, 1, 2, 2)\n",
      "w_head_k (8, 1, 2, 2)\n",
      "Eager execution: False\n",
      "AC Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/einsum/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "r_head_k (8, 2, 2)\n",
      "BD Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/einsum_1/Einsum:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "BD_rel_shift Tensor(\"replica_1/tf_transfo_xllm_head_model/transformer/layers_._5/dec_attn/Reshape_5:0\", shape=(3, 8, 1, 2), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 96 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 4 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Error reported to Coordinator: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 276, in _call_for_each_replica\n",
      "    merge_result = threads[0].merge_fn(distribution, *merge_args,\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 377, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n",
      "    distribution.extended.update(\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2637, in update\n",
      "    return self._update(var, fn, args, kwargs, group)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 801, in _update\n",
      "    fn(v, *distribute_utils.select_replica(i, args),\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 689, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 331, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options, False)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 458, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n",
      "    return self._update_step_xla(grad, var, id(self._var_key(var)))\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 919, in _call\n",
      "    results = self._variable_creation_fn(*args, **kwds)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 133, in __call__\n",
      "    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 370, in _maybe_define_function\n",
      "    function_context.make_cache_key((args, kwargs), captures))\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py\", line 133, in make_cache_key\n",
      "    args_signature = trace_type.from_value(\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py\", line 124, in from_value\n",
      "    if util.is_namedtuple(value):\n",
      "  File \"/home/jun/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/core/function/trace_type/util.py\", line 20, in is_namedtuple\n",
      "    return hasattr(obj, \"_fields\") and all(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/workspace/transfo_xl/multi.ipynb 셀 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/transfo_xl/multi.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_dist_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/transfo_xl/multi.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m   data,target\u001b[39m=\u001b[39mx\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/transfo_xl/multi.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m   mems,loss \u001b[39m=\u001b[39m distributed_train_step(data,target,mems)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/transfo_xl/multi.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m   total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224a554e227d/home/jun/workspace/transfo_xl/multi.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m   num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:928\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 928\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    929\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    931\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:749\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    750\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    751\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    754\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:162\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 162\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:645\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 645\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    646\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1258\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1258\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1259\u001b[0m       original_func,\n\u001b[1;32m   1260\u001b[0m       args,\n\u001b[1;32m   1261\u001b[0m       kwargs,\n\u001b[1;32m   1262\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1263\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1264\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1265\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1266\u001b[0m       ))\n\u001b[1;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file3k_6e9ua.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__distributed_train_step\u001b[0;34m(dataset_inputs, target, mems)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m (mems, per_replica_losses) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(strategy)\u001b[39m.\u001b[39;49mrun, (ag__\u001b[39m.\u001b[39;49mld(train_step),), \u001b[39mdict\u001b[39;49m(args\u001b[39m=\u001b[39;49m(ag__\u001b[39m.\u001b[39;49mld(dataset_inputs), ag__\u001b[39m.\u001b[39;49mld(target), ag__\u001b[39m.\u001b[39;49mld(mems))), fscope)\n\u001b[1;32m     11\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:696\u001b[0m, in \u001b[0;36mMirroredExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m--> 696\u001b[0m   \u001b[39mreturn\u001b[39;00m mirrored_run\u001b[39m.\u001b[39;49mcall_for_each_replica(\n\u001b[1;32m    697\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_container_strategy(), fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:101\u001b[0m, in \u001b[0;36mcall_for_each_replica\u001b[0;34m(strategy, fn, args, kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m   \u001b[39m# When a tf.function is wrapped to trigger _call_for_each_replica (see\u001b[39;00m\n\u001b[1;32m     95\u001b[0m   \u001b[39m# the other branch above), AutoGraph stops conversion at\u001b[39;00m\n\u001b[1;32m     96\u001b[0m   \u001b[39m# _call_for_each_replica itself (TF library functions are allowlisted).\u001b[39;00m\n\u001b[1;32m     97\u001b[0m   \u001b[39m# This makes sure that the Python function that originally passed to\u001b[39;00m\n\u001b[1;32m     98\u001b[0m   \u001b[39m# the tf.function is still converted.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m _call_for_each_replica(strategy, fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:283\u001b[0m, in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m threads:\n\u001b[1;32m    282\u001b[0m     t\u001b[39m.\u001b[39mshould_run\u001b[39m.\u001b[39mset()\n\u001b[0;32m--> 283\u001b[0m   coord\u001b[39m.\u001b[39;49mjoin(threads)\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m distribute_utils\u001b[39m.\u001b[39mregroup(\u001b[39mtuple\u001b[39m(t\u001b[39m.\u001b[39mmain_result \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m threads))\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:386\u001b[0m, in \u001b[0;36mCoordinator.join\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info_to_raise:\n\u001b[1;32m    385\u001b[0m   _, ex_instance, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exc_info_to_raise\n\u001b[0;32m--> 386\u001b[0m   \u001b[39mraise\u001b[39;00m ex_instance\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m stragglers:\n\u001b[1;32m    388\u001b[0m   \u001b[39mif\u001b[39;00m ignore_live_threads:\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py:293\u001b[0m, in \u001b[0;36mCoordinator.stop_on_exception\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Context manager to request stop when an Exception is raised.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \n\u001b[1;32m    265\u001b[0m \u001b[39mCode that uses a coordinator must catch exceptions and pass\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m  nothing.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m   \u001b[39myield\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39mexcept\u001b[39;00m:  \u001b[39m# pylint: disable=bare-except\u001b[39;00m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_stop(ex\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexc_info())\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py:276\u001b[0m, in \u001b[0;36m_call_for_each_replica\u001b[0;34m(distribution, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39m# Control is transfered from _MirroredReplicaThread (MRT) to the main\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m# thread, i.e., here, to perform `merge_fn`, and thus we preserve the\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m# name scope,  control dependencies, etc. from MRT at the time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m# mode scope as well so that `merge_fn` does not have trouble\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m# accessing resources defined in MRT under the same context.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\n\u001b[1;32m    272\u001b[0m     mtt_captured_name_scope), ops\u001b[39m.\u001b[39mcontrol_dependencies(\n\u001b[1;32m    273\u001b[0m         mtt_captured_control_deps), variable_scope\u001b[39m.\u001b[39mvariable_scope(\n\u001b[1;32m    274\u001b[0m             mtt_captured_var_scope), _maybe_enter_eager_mode(\n\u001b[1;32m    275\u001b[0m                 threads[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmerge_call_entered_in_eager):\n\u001b[0;32m--> 276\u001b[0m   merge_result \u001b[39m=\u001b[39m threads[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mmerge_fn(distribution, \u001b[39m*\u001b[39;49mmerge_args,\n\u001b[1;32m    277\u001b[0m                                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmerge_kwargs)\n\u001b[1;32m    278\u001b[0m \u001b[39mfor\u001b[39;00m r, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(threads):\n\u001b[1;32m    279\u001b[0m   t\u001b[39m.\u001b[39mmerge_result \u001b[39m=\u001b[39m distribute_utils\u001b[39m.\u001b[39mselect_replica(r, merge_result)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1216\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1215\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1216\u001b[0m     distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m   1217\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[1;32m   1221\u001b[0m     _, var_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py:801\u001b[0m, in \u001b[0;36mMirroredExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m    795\u001b[0m   name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mupdate_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m i\n\u001b[1;32m    796\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mdevice(v\u001b[39m.\u001b[39mdevice), \\\n\u001b[1;32m    797\u001b[0m        distribute_lib\u001b[39m.\u001b[39mUpdateContext(i), \\\n\u001b[1;32m    798\u001b[0m        ops\u001b[39m.\u001b[39mname_scope(name):\n\u001b[1;32m    799\u001b[0m     \u001b[39m# If args and kwargs are not mirrored, the value is returned as is.\u001b[39;00m\n\u001b[1;32m    800\u001b[0m     updates\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 801\u001b[0m         fn(v, \u001b[39m*\u001b[39;49mdistribute_utils\u001b[39m.\u001b[39;49mselect_replica(i, args),\n\u001b[1;32m    802\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdistribute_utils\u001b[39m.\u001b[39;49mselect_replica(i, kwargs)))\n\u001b[1;32m    803\u001b[0m \u001b[39mreturn\u001b[39;00m distribute_utils\u001b[39m.\u001b[39mupdate_regroup(\u001b[39mself\u001b[39m, updates, group)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1211\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1211\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_step_xla(grad, var, \u001b[39mid\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_var_key(var)))\n\u001b[1;32m   1212\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:370\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m captures \u001b[39m=\u001b[39m graph_capture_container\u001b[39m.\u001b[39mget_snapshot()\n\u001b[1;32m    368\u001b[0m \u001b[39m# Create a cache_key with args and captures\u001b[39;00m\n\u001b[1;32m    369\u001b[0m traced_func_key, traced_func_deletion_observer \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 370\u001b[0m     function_context\u001b[39m.\u001b[39;49mmake_cache_key((args, kwargs), captures))\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(traced_func_key,\n\u001b[1;32m    373\u001b[0m                          traced_func_deletion_observer,\n\u001b[1;32m    374\u001b[0m                          concrete_function)\n\u001b[1;32m    376\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function, filtered_flat_args\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:133\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    131\u001b[0m   captures \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    132\u001b[0m signature_context \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mInternalTracingContext()\n\u001b[0;32m--> 133\u001b[0m args_signature \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39;49mfrom_value(\n\u001b[1;32m    134\u001b[0m     args, signature_context)\n\u001b[1;32m    135\u001b[0m captures_dict_tracetype \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(\n\u001b[1;32m    136\u001b[0m     captures, signature_context)\n\u001b[1;32m    138\u001b[0m \u001b[39m# TODO(fmuham): Use the actual FunctionType\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:124\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mList(\u001b[39m*\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m   \u001b[39mif\u001b[39;00m util\u001b[39m.\u001b[39;49mis_namedtuple(value):\n\u001b[1;32m    125\u001b[0m     named_tuple_type \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(value)\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mNamedTuple\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    127\u001b[0m         named_tuple_type, \u001b[39mtuple\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n",
      "File \u001b[0;32m~/miniconda3/envs/new/lib/python3.8/site-packages/tensorflow/core/function/trace_type/util.py:20\u001b[0m, in \u001b[0;36mis_namedtuple\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_namedtuple\u001b[39m(obj):\n\u001b[0;32m---> 20\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(obj, \u001b[39m\"\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m     21\u001b[0m       \u001b[39misinstance\u001b[39m(field, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m field \u001b[39min\u001b[39;00m obj\u001b[39m.\u001b[39m_fields)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  mems = None\n",
    "  total_loss = 0.0\n",
    "  num_batches = 0\n",
    "  with tf.profiler.experimental.Trace('train', step_num=epoch, _r=1):\n",
    "    for x in train_dist_dataset:\n",
    "      data,target=x\n",
    "      mems,loss = distributed_train_step(data,target,mems)\n",
    "      total_loss += loss.numpy()\n",
    "      num_batches += 1\n",
    "      \n",
    "      if num_batches % 50 == 0:\n",
    "        print(f'Epoch {epoch + 1} Batch {num_batches} Loss {loss}')\n",
    "      \n",
    "    train_loss = total_loss / num_batches\n",
    "      \n",
    "      \n",
    "    template = (\"Epoch {}, Loss: {} \")\n",
    "    print(template.format(epoch + 1, train_loss,\n",
    "                          )) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:\n",
      "[[[[ 1  2]]\n",
      "\n",
      "  [[ 3  4]]\n",
      "\n",
      "  [[ 5  6]]\n",
      "\n",
      "  [[ 7  8]]\n",
      "\n",
      "  [[ 9 10]]\n",
      "\n",
      "  [[11 12]]\n",
      "\n",
      "  [[13 14]]\n",
      "\n",
      "  [[15 16]]]\n",
      "\n",
      "\n",
      " [[[17 18]]\n",
      "\n",
      "  [[19 20]]\n",
      "\n",
      "  [[21 22]]\n",
      "\n",
      "  [[23 24]]\n",
      "\n",
      "  [[25 26]]\n",
      "\n",
      "  [[27 28]]\n",
      "\n",
      "  [[29 30]]\n",
      "\n",
      "  [[31 32]]]\n",
      "\n",
      "\n",
      " [[[33 34]]\n",
      "\n",
      "  [[35 36]]\n",
      "\n",
      "  [[37 38]]\n",
      "\n",
      "  [[39 40]]\n",
      "\n",
      "  [[41 42]]\n",
      "\n",
      "  [[43 44]]\n",
      "\n",
      "  [[45 46]]\n",
      "\n",
      "  [[47 48]]]]\n",
      "\n",
      "Result after applying _rel_shift:\n",
      "[[[[ 5  6]]\n",
      "\n",
      "  [[ 7  8]]\n",
      "\n",
      "  [[ 9 10]]\n",
      "\n",
      "  [[11 12]]\n",
      "\n",
      "  [[13 14]]\n",
      "\n",
      "  [[15 16]]\n",
      "\n",
      "  [[ 0  0]]\n",
      "\n",
      "  [[17 18]]]\n",
      "\n",
      "\n",
      " [[[19 20]]\n",
      "\n",
      "  [[21 22]]\n",
      "\n",
      "  [[23 24]]\n",
      "\n",
      "  [[25 26]]\n",
      "\n",
      "  [[27 28]]\n",
      "\n",
      "  [[29 30]]\n",
      "\n",
      "  [[31 32]]\n",
      "\n",
      "  [[ 0  0]]]\n",
      "\n",
      "\n",
      " [[[33 34]]\n",
      "\n",
      "  [[35 36]]\n",
      "\n",
      "  [[37 38]]\n",
      "\n",
      "  [[39 40]]\n",
      "\n",
      "  [[41 42]]\n",
      "\n",
      "  [[43 44]]\n",
      "\n",
      "  [[45 46]]\n",
      "\n",
      "  [[47 48]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the _rel_shift function\n",
    "def _rel_shift(x):\n",
    "    x_size = x.shape.as_list()\n",
    "\n",
    "    x = tf.pad(x, [[0, 0], [1, 0], [0, 0], [0, 0]])\n",
    "    x = tf.reshape(x, [x_size[1] + 1, x_size[0], x_size[2], x_size[3]])\n",
    "    x = tf.slice(x, [1, 0, 0, 0], [-1, -1, -1, -1])\n",
    "    x = tf.reshape(x, x_size)\n",
    "\n",
    "    return x\n",
    "def _rel_shift(self, x):\n",
    "        x_size = shape_list(x)\n",
    "\n",
    "        x = tf.pad(x, [[0, 0], [1, 0], [0, 0], [0, 0]])\n",
    "        x = tf.reshape(x, [x_size[1] + 1, x_size[0], x_size[2], x_size[3]])\n",
    "        x = tf.slice(x, [1, 0, 0, 0], [-1, -1, -1, -1])\n",
    "        x = tf.reshape(x, x_size)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Create a sample tensor x with shape (3, 8, 1, 2)\n",
    "x = tf.constant([[[[1, 2]], [[3, 4]], [[5, 6]], [[7, 8]], [[9, 10]], [[11, 12]], [[13, 14]], [[15, 16]]],\n",
    "                 [[[17, 18]], [[19, 20]], [[21, 22]], [[23, 24]], [[25, 26]], [[27, 28]], [[29, 30]], [[31, 32]]],\n",
    "                 [[[33, 34]], [[35, 36]], [[37, 38]], [[39, 40]], [[41, 42]], [[43, 44]], [[45, 46]], [[47, 48]]]])\n",
    "\n",
    "# Apply the _rel_shift function to x\n",
    "result = _rel_shift(x)\n",
    "\n",
    "# Print the original and result tensors\n",
    "print(\"Original x:\")\n",
    "print(x.numpy())\n",
    "print(\"\\nResult after applying _rel_shift:\")\n",
    "print(result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def _rel_shift(x):\n",
    "  x_size = tf.shape(x)\n",
    "\n",
    "  x = tf.pad(x, [[0, 0], [1, 0], [0, 0], [0, 0]])\n",
    "  x = tf.reshape(x, [x_size[1] + 1, x_size[0], x_size[2], x_size[3]])\n",
    "  x = tf.slice(x, [1, 0, 0, 0], [-1, -1, -1, -1])\n",
    "  x = tf.reshape(x, x_size)\n",
    "\n",
    "  return x\n",
    "\n",
    "\n",
    "# Define tensors based on your scenario\n",
    "rr_head_q = tf.constant([[[[6, 6], [6, 6]]], [[[7, 7], [7, 7]]], [[[8, 8], [8, 8]]]], dtype=tf.float32)  # Shape: (3,1,2,2)\n",
    "rw_head_q = tf.constant([[[[6, 6], [6, 6]]], [[[7, 7], [7, 7]]], [[[8, 8], [8, 8]]]], dtype=tf.float32)  # Shape: (3,1,2,2)\n",
    "w_head_k = tf.constant([[[[1, 1], [1, 1]]], [[[2, 2], [2, 2]]], [[[3, 3], [3, 3]]], [[[4, 4], [4, 4]]], [[[5, 5], [5, 5]]], [[[6, 6], [6, 6]]], [[[7, 7], [7, 7]]], [[[8, 8], [8, 8]]]], dtype=tf.float32)  # Shape: (8,1,2,2)\n",
    "r_head_k = tf.constant([[[1.1, 1.2], [1.3, 1.4]], [[2.1, 2.2], [2.3, 2.4]], [[3.1, 3.2], [3.3, 3.4]], [[4.1, 4.2], [4.3, 4.4]], [[5.1, 5.2], [5.3, 5.4]], [[6.1, 6.2], [6.3, 6.4]], [[7.1, 7.2], [7.3, 7.4]], [[8.1, 8.2], [8.3, 8.4]]], dtype=tf.float32)  # Shape: (8,2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_head_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute AC\n",
    "AC = tf.einsum(\"ibnd,jbnd->ijbn\", rw_head_q, w_head_k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8, 1, 2), dtype=float32, numpy=\n",
       "array([[[[ 12.,  12.]],\n",
       "\n",
       "        [[ 24.,  24.]],\n",
       "\n",
       "        [[ 36.,  36.]],\n",
       "\n",
       "        [[ 48.,  48.]],\n",
       "\n",
       "        [[ 60.,  60.]],\n",
       "\n",
       "        [[ 72.,  72.]],\n",
       "\n",
       "        [[ 84.,  84.]],\n",
       "\n",
       "        [[ 96.,  96.]]],\n",
       "\n",
       "\n",
       "       [[[ 14.,  14.]],\n",
       "\n",
       "        [[ 28.,  28.]],\n",
       "\n",
       "        [[ 42.,  42.]],\n",
       "\n",
       "        [[ 56.,  56.]],\n",
       "\n",
       "        [[ 70.,  70.]],\n",
       "\n",
       "        [[ 84.,  84.]],\n",
       "\n",
       "        [[ 98.,  98.]],\n",
       "\n",
       "        [[112., 112.]]],\n",
       "\n",
       "\n",
       "       [[[ 16.,  16.]],\n",
       "\n",
       "        [[ 32.,  32.]],\n",
       "\n",
       "        [[ 48.,  48.]],\n",
       "\n",
       "        [[ 64.,  64.]],\n",
       "\n",
       "        [[ 80.,  80.]],\n",
       "\n",
       "        [[ 96.,  96.]],\n",
       "\n",
       "        [[112., 112.]],\n",
       "\n",
       "        [[128., 128.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute BD\n",
    "BD = tf.einsum(\"ibnd,jnd->ijbn\", rr_head_q, r_head_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8, 1, 2), dtype=float32, numpy=\n",
       "array([[[[ 13.800001,  16.199999]],\n",
       "\n",
       "        [[ 25.8     ,  28.2     ]],\n",
       "\n",
       "        [[ 37.8     ,  40.2     ]],\n",
       "\n",
       "        [[ 49.799995,  52.200005]],\n",
       "\n",
       "        [[ 61.799995,  64.200005]],\n",
       "\n",
       "        [[ 73.799995,  76.200005]],\n",
       "\n",
       "        [[ 85.799995,  88.200005]],\n",
       "\n",
       "        [[ 97.8     , 100.2     ]]],\n",
       "\n",
       "\n",
       "       [[[ 16.1     ,  18.9     ]],\n",
       "\n",
       "        [[ 30.099998,  32.9     ]],\n",
       "\n",
       "        [[ 44.1     ,  46.9     ]],\n",
       "\n",
       "        [[ 58.1     ,  60.9     ]],\n",
       "\n",
       "        [[ 72.1     ,  74.9     ]],\n",
       "\n",
       "        [[ 86.1     ,  88.9     ]],\n",
       "\n",
       "        [[100.1     , 102.9     ]],\n",
       "\n",
       "        [[114.100006, 116.899994]]],\n",
       "\n",
       "\n",
       "       [[[ 18.400002,  21.599998]],\n",
       "\n",
       "        [[ 34.4     ,  37.6     ]],\n",
       "\n",
       "        [[ 50.4     ,  53.6     ]],\n",
       "\n",
       "        [[ 66.399994,  69.600006]],\n",
       "\n",
       "        [[ 82.399994,  85.600006]],\n",
       "\n",
       "        [[ 98.399994, 101.600006]],\n",
       "\n",
       "        [[114.399994, 117.600006]],\n",
       "\n",
       "        [[130.4     , 133.6     ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8, 1, 2), dtype=float32, numpy=\n",
       "array([[[[ 37.8     ,  40.2     ]],\n",
       "\n",
       "        [[ 49.799995,  52.200005]],\n",
       "\n",
       "        [[ 61.799995,  64.200005]],\n",
       "\n",
       "        [[ 73.799995,  76.200005]],\n",
       "\n",
       "        [[ 85.799995,  88.200005]],\n",
       "\n",
       "        [[ 97.8     , 100.2     ]],\n",
       "\n",
       "        [[  0.      ,   0.      ]],\n",
       "\n",
       "        [[ 16.1     ,  18.9     ]]],\n",
       "\n",
       "\n",
       "       [[[ 30.099998,  32.9     ]],\n",
       "\n",
       "        [[ 44.1     ,  46.9     ]],\n",
       "\n",
       "        [[ 58.1     ,  60.9     ]],\n",
       "\n",
       "        [[ 72.1     ,  74.9     ]],\n",
       "\n",
       "        [[ 86.1     ,  88.9     ]],\n",
       "\n",
       "        [[100.1     , 102.9     ]],\n",
       "\n",
       "        [[114.100006, 116.899994]],\n",
       "\n",
       "        [[  0.      ,   0.      ]]],\n",
       "\n",
       "\n",
       "       [[[ 18.400002,  21.599998]],\n",
       "\n",
       "        [[ 34.4     ,  37.6     ]],\n",
       "\n",
       "        [[ 50.4     ,  53.6     ]],\n",
       "\n",
       "        [[ 66.399994,  69.600006]],\n",
       "\n",
       "        [[ 82.399994,  85.600006]],\n",
       "\n",
       "        [[ 98.399994, 101.600006]],\n",
       "\n",
       "        [[114.399994, 117.600006]],\n",
       "\n",
       "        [[130.4     , 133.6     ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply _rel_shift to BD\n",
    "BD_shifted = _rel_shift(BD)\n",
    "BD_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC: [[[[ 12.  12.]]\n",
      "\n",
      "  [[ 24.  24.]]\n",
      "\n",
      "  [[ 36.  36.]]\n",
      "\n",
      "  [[ 48.  48.]]\n",
      "\n",
      "  [[ 60.  60.]]\n",
      "\n",
      "  [[ 72.  72.]]\n",
      "\n",
      "  [[ 84.  84.]]\n",
      "\n",
      "  [[ 96.  96.]]]\n",
      "\n",
      "\n",
      " [[[ 14.  14.]]\n",
      "\n",
      "  [[ 28.  28.]]\n",
      "\n",
      "  [[ 42.  42.]]\n",
      "\n",
      "  [[ 56.  56.]]\n",
      "\n",
      "  [[ 70.  70.]]\n",
      "\n",
      "  [[ 84.  84.]]\n",
      "\n",
      "  [[ 98.  98.]]\n",
      "\n",
      "  [[112. 112.]]]\n",
      "\n",
      "\n",
      " [[[ 16.  16.]]\n",
      "\n",
      "  [[ 32.  32.]]\n",
      "\n",
      "  [[ 48.  48.]]\n",
      "\n",
      "  [[ 64.  64.]]\n",
      "\n",
      "  [[ 80.  80.]]\n",
      "\n",
      "  [[ 96.  96.]]\n",
      "\n",
      "  [[112. 112.]]\n",
      "\n",
      "  [[128. 128.]]]]\n",
      "BD before shift: [[[[ 13.800001  16.199999]]\n",
      "\n",
      "  [[ 25.8       28.2     ]]\n",
      "\n",
      "  [[ 37.8       40.2     ]]\n",
      "\n",
      "  [[ 49.799995  52.200005]]\n",
      "\n",
      "  [[ 61.799995  64.200005]]\n",
      "\n",
      "  [[ 73.799995  76.200005]]\n",
      "\n",
      "  [[ 85.799995  88.200005]]\n",
      "\n",
      "  [[ 97.8      100.2     ]]]\n",
      "\n",
      "\n",
      " [[[ 16.1       18.9     ]]\n",
      "\n",
      "  [[ 30.099998  32.9     ]]\n",
      "\n",
      "  [[ 44.1       46.9     ]]\n",
      "\n",
      "  [[ 58.1       60.9     ]]\n",
      "\n",
      "  [[ 72.1       74.9     ]]\n",
      "\n",
      "  [[ 86.1       88.9     ]]\n",
      "\n",
      "  [[100.1      102.9     ]]\n",
      "\n",
      "  [[114.100006 116.899994]]]\n",
      "\n",
      "\n",
      " [[[ 18.400002  21.599998]]\n",
      "\n",
      "  [[ 34.4       37.6     ]]\n",
      "\n",
      "  [[ 50.4       53.6     ]]\n",
      "\n",
      "  [[ 66.399994  69.600006]]\n",
      "\n",
      "  [[ 82.399994  85.600006]]\n",
      "\n",
      "  [[ 98.399994 101.600006]]\n",
      "\n",
      "  [[114.399994 117.600006]]\n",
      "\n",
      "  [[130.4      133.6     ]]]]\n",
      "BD after shift: [[[[ 37.8       40.2     ]]\n",
      "\n",
      "  [[ 49.799995  52.200005]]\n",
      "\n",
      "  [[ 61.799995  64.200005]]\n",
      "\n",
      "  [[ 73.799995  76.200005]]\n",
      "\n",
      "  [[ 85.799995  88.200005]]\n",
      "\n",
      "  [[ 97.8      100.2     ]]\n",
      "\n",
      "  [[  0.         0.      ]]\n",
      "\n",
      "  [[ 16.1       18.9     ]]]\n",
      "\n",
      "\n",
      " [[[ 30.099998  32.9     ]]\n",
      "\n",
      "  [[ 44.1       46.9     ]]\n",
      "\n",
      "  [[ 58.1       60.9     ]]\n",
      "\n",
      "  [[ 72.1       74.9     ]]\n",
      "\n",
      "  [[ 86.1       88.9     ]]\n",
      "\n",
      "  [[100.1      102.9     ]]\n",
      "\n",
      "  [[114.100006 116.899994]]\n",
      "\n",
      "  [[  0.         0.      ]]]\n",
      "\n",
      "\n",
      " [[[ 18.400002  21.599998]]\n",
      "\n",
      "  [[ 34.4       37.6     ]]\n",
      "\n",
      "  [[ 50.4       53.6     ]]\n",
      "\n",
      "  [[ 66.399994  69.600006]]\n",
      "\n",
      "  [[ 82.399994  85.600006]]\n",
      "\n",
      "  [[ 98.399994 101.600006]]\n",
      "\n",
      "  [[114.399994 117.600006]]\n",
      "\n",
      "  [[130.4      133.6     ]]]]\n",
      "Attention Score: [[[[ 49.8       52.2     ]]\n",
      "\n",
      "  [[ 73.799995  76.200005]]\n",
      "\n",
      "  [[ 97.799995 100.200005]]\n",
      "\n",
      "  [[121.799995 124.200005]]\n",
      "\n",
      "  [[145.79999  148.20001 ]]\n",
      "\n",
      "  [[169.8      172.2     ]]\n",
      "\n",
      "  [[ 84.        84.      ]]\n",
      "\n",
      "  [[112.1      114.9     ]]]\n",
      "\n",
      "\n",
      " [[[ 44.1       46.9     ]]\n",
      "\n",
      "  [[ 72.1       74.9     ]]\n",
      "\n",
      "  [[100.1      102.9     ]]\n",
      "\n",
      "  [[128.1      130.9     ]]\n",
      "\n",
      "  [[156.1      158.9     ]]\n",
      "\n",
      "  [[184.1      186.9     ]]\n",
      "\n",
      "  [[212.1      214.9     ]]\n",
      "\n",
      "  [[112.       112.      ]]]\n",
      "\n",
      "\n",
      " [[[ 34.4       37.6     ]]\n",
      "\n",
      "  [[ 66.4       69.6     ]]\n",
      "\n",
      "  [[ 98.4      101.6     ]]\n",
      "\n",
      "  [[130.4      133.6     ]]\n",
      "\n",
      "  [[162.4      165.6     ]]\n",
      "\n",
      "  [[194.4      197.6     ]]\n",
      "\n",
      "  [[226.4      229.6     ]]\n",
      "\n",
      "  [[258.4      261.6     ]]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the final attention score\n",
    "attn_score = AC + BD_shifted\n",
    "\n",
    "print('AC:', AC.numpy())\n",
    "print('BD before shift:', BD.numpy())\n",
    "print('BD after shift:', BD_shifted.numpy())\n",
    "print('Attention Score:', attn_score.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3,1) (3,3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/jun/workspace/transfo_xl/multi.ipynb 셀 31\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m unshifted_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     [\u001b[39m0.00\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.02\u001b[39m, \u001b[39m0.03\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     [\u001b[39m0.10\u001b[39m, \u001b[39m0.11\u001b[39m, \u001b[39m0.12\u001b[39m, \u001b[39m0.13\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     [\u001b[39m0.20\u001b[39m, \u001b[39m0.21\u001b[39m, \u001b[39m0.22\u001b[39m, \u001b[39m0.23\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Apply the relative shift\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m shifted_array \u001b[39m=\u001b[39m rel_shift_numpy(unshifted_array)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m shifted_array\n",
      "\u001b[1;32m/home/jun/workspace/transfo_xl/multi.ipynb 셀 31\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Mask out the upper triangle\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtriu(np\u001b[39m.\u001b[39mones((x_padded\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], x_padded\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])), k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m x_masked \u001b[39m=\u001b[39m x_padded \u001b[39m*\u001b[39;49m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m mask[:, :, \u001b[39mNone\u001b[39;49;00m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B119.69.75.176/home/jun/workspace/transfo_xl/multi.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x_masked\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3,1) (3,3,1) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the transformation function\n",
    "def rel_shift_numpy(x):\n",
    "    # Append one \"column\" of zeros to the left\n",
    "    zero_pad = np.zeros((x.shape[0], 1))\n",
    "    x_padded = np.concatenate([zero_pad, x], axis=1)\n",
    "\n",
    "    # Reshape the matrix by shifting the elements in the last dimension\n",
    "    x_padded = x_padded.reshape(x.shape[1] + 1, x.shape[0], -1)\n",
    "\n",
    "    # Remove the first \"row\"\n",
    "    x_padded = x_padded[1:, :, :]\n",
    "\n",
    "    # Mask out the upper triangle\n",
    "    mask = np.triu(np.ones((x_padded.shape[1], x_padded.shape[1])), k=1)\n",
    "    x_masked = x_padded * (1 - mask[:, :, None])\n",
    "\n",
    "    return x_masked.transpose(1, 0, 2)\n",
    "\n",
    "# Create the initial unshifted array based on the provided image\n",
    "unshifted_array = np.array([\n",
    "    [0.00, 0.01, 0.02, 0.03],\n",
    "    [0.10, 0.11, 0.12, 0.13],\n",
    "    [0.20, 0.21, 0.22, 0.23]\n",
    "])\n",
    "\n",
    "# Apply the relative shift\n",
    "shifted_array = rel_shift_numpy(unshifted_array)\n",
    "\n",
    "shifted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
